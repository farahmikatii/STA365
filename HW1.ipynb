{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f81eb51",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Homework #1: AB-testing<br>and the Multi-Armed Bayesian Bandit\n",
    "\n",
    "### You have three choices... choose wisely, my friends...\n",
    "\n",
    "\n",
    "|Option|The \"Red\" one|The \"Blue\" one|The \"Other\" one|\n",
    "|-|-|-|-|\n",
    "|Unknown Probability of Success|$\\theta_A$ | $\\theta_B$ | $\\theta_C$ |\n",
    "\n",
    "$$p(\\theta_j|x_j,n_j) \\propto \\theta^{x_j+\\alpha_j-1}(1-\\theta_j)^{n-x+\\beta_j-1}  \\Rightarrow \\; \\text{What distribution?}$$\n",
    "\n",
    "- Try one out, and collect that data update...\n",
    "    - What's the data?\n",
    "    - What's the update for the posterior in question?\n",
    "- Which one of the three choices will you try out? How will you choose? \n",
    "\n",
    "\n",
    "- Hints: <u>You can use *simulation* to find out the *relative belief* (i.e., probability) that each of the choices is the best.</u> Posterior distributions characterize your beliefs about the parameters $\\theta_A, \\theta_B$ and $\\theta_C$. What can you learn by repeatedly sampling values from the posterior distribution while comparing the values of each triplet? If you know the chances that A, B, and C are the best choice, how could you balance ***exploration versus exploitation*** when choosing which of the possible options to collect the next data point on next?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d51fc97",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We begin by defining the parameters $\\theta_A = 0.5, \\theta_B = 0.4, \\theta_C = 0.1$.\n",
    "As defined in the problem, we begin with an understanding that the probability of success for the \"Red\", \"Blue\" and \"Other\" are given by the Beta distribution. \n",
    "To select the game with the highest probability of success, I begin by selecting one of the options assuming the highest probability of success is the same initially across all games, I would then play that game 10 times and then compute the posterior distribution for all games with this updated data. Afterwards, the probability of each game has changed, and I would choose the game with the highest probability and repeat this process 100 times until the best game is found. \n",
    "\n",
    "\n",
    "The data we collect will be after playing the game selected, and will be the number of success and losses. Based on this data, we update the posterior for each game, in particular, adding 1 to the alpha prior if the game is a success and 1 to the beta prior if the game is a loss. Initially, all three choices can be chosen randomly since their probabilities of success follow a beta distribution. \n",
    "\n",
    "By repeatedly sampling values from the posterior distribution while comparing the values of each triplet, this updating process helps in making informed decisions based on the latest available information. Explorations versus exploitation is balanced when choosing the possible options to collect the next data point as there is a tradeoff between exploring games to learn more about their success and exploiting the information we already have to maxmize the expected success of a game. If we know a particular game has a higher probability of success, we \"exploit\" that knowledge by using it as the next game in the simulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c90f5566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Probabilities:\n",
      "Red: Probability=0.22321428571428573\n",
      "Blue: Probability=0.26327433628318586\n",
      "Other: Probability=0.2895927601809955\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def update_beta_prior(alpha_prior, beta_prior, successes, trials):\n",
    "    alpha_posterior = alpha_prior + successes\n",
    "    beta_posterior = beta_prior + trials - successes\n",
    "    return (alpha_posterior, beta_posterior)\n",
    "\n",
    "# Initial parameters for each option\n",
    "options = [\"Red\", \"Blue\", \"Other\"]\n",
    "alpha_priors = {\"Red\": 1, \"Blue\": 1, \"Other\": 1}\n",
    "beta_priors = {\"Red\": 1, \"Blue\": 1, \"Other\": 1}\n",
    "posteriors = {\"Red\": [], \"Blue\": [] , \"Other\": []}\n",
    "\n",
    "initial_parameters = {\"Red\": 0.5, \"Blue\": 0.4, \"Other\": 0.1}\n",
    "current_probabilities = initial_parameters.copy()\n",
    "\n",
    "# Arbitrarily choosing number of iterations of updating \n",
    "num_iterations = 100\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    # Initially, all games have same probability so the first game is chosen\n",
    "    # After initial run, the game with the largest probability is chosen\n",
    "    chosen_option = max(current_probabilities, key=current_probabilities.get)\n",
    "    \n",
    "    # Simulate playing the chosen option\n",
    "    success = stats.binom(n=10, p=current_probabilities[chosen_option]).rvs(size=1)[0] \n",
    "        \n",
    "    # Update posteriors\n",
    "    alpha_priors[chosen_option], beta_priors[chosen_option] = update_beta_prior(\n",
    "        alpha_priors[chosen_option], beta_priors[chosen_option], success, 10\n",
    "    )\n",
    "    \n",
    "    # Update current probabilities of each game \n",
    "    for option in options:\n",
    "        current_probabilities[option] = stats.binom.pmf(success, 10, initial_parameters[option])\n",
    "\n",
    "    # Store posteriors for analysis\n",
    "    for option in options:\n",
    "        posteriors[option].append((alpha_priors[option], beta_priors[option]))\n",
    "    \n",
    "print(\"Final Probabilities:\")\n",
    "for option in options:\n",
    "    final_posterior = stats.beta(alpha_priors[option], beta_priors[option])\n",
    "    probability = final_posterior.mean()\n",
    "    print(f\"{option}: Probability={probability}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf86716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
